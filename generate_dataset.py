# -*- coding: utf-8 -*-
"""generate_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LhdAo0b5486_mJ5SS-O-lDGKG1tHEoG1
"""

!pip install DeepFace

from deepface import DeepFace
import numpy as np
import pandas as pd
import os
import cv2

dataset = []

# create columns name of dataset

columns_names = ['label', 'file_name']
for i in range(512):
  columns_names.append('feature'+str(i+1))

print(columns_names)

def generate_dataset(img_path):
  embedding_objs = DeepFace.represent(img_path=img_path, enforce_detection=False, model_name="ArcFace")
  # embedding_objs dictionary have 2 keys (embedding & facial_area). We just need embedding which is a 512 lenght list
  #print(embedding_objs[0]['embedding'])
  # lenght of embedding features (512)
  #print(len(embedding_objs[0]['embedding']))
  return embedding_objs[0]['embedding']

rootdir = "/content/drive/MyDrive/PersianFace"
labels = os.listdir(rootdir)

for root, folders, images in os.walk(rootdir):

  for file_name in images:
    features = generate_dataset(os.path.join(root, file_name))
    features.insert(0, os.path.basename(root))
    features.insert(1, file_name)
    #print(os.path.basename(root))
    #print(features)
    dataset.append(features)

dataset = pd.DataFrame(dataset,columns=columns_names)
dataset.to_csv('Dataset.csv',index=False)

dataset = pd.read_csv('Dataset.csv')
dataset

labels_array = dataset["label"].unique()
labels_array

dataset["label"]

dataset['label_id'] = dataset.groupby(['label']).ngroup()
dataset

from sklearn.model_selection import train_test_split
import tensorflow as tf

x_train = np.array(dataset.loc[:,'feature1':'feature512'])
#print(x_train)
y_train = np.array(dataset['label_id'])
print(x_train.shape)
print(y_train.shape)

x_train ,  x_test , y_train , y_test = train_test_split(x_train ,y_train ,  test_size=0.2)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

y_train = y_train.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)
print(y_train.shape, y_test.shape)

x_train, x_test = x_train/255.0, x_test/255.0

model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(512,)),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(30, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=200)
model.evaluate(x_test, y_test)

import matplotlib.pyplot as plt

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(1024,input_dim=512,activation=None),
    tf.keras.layers.Dense(512,activation='elu'),
    tf.keras.layers.Dense(256,activation='elu'),
    tf.keras.layers.Dense(128,activation='elu'),
    tf.keras.layers.Dense(64,activation='elu'),
    tf.keras.layers.Dense(30,activation="softmax")
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=100)
model.evaluate(x_test, y_test)